# Задание 1: Основы C++ и OpenMP

В этом репозитории содержатся решения для Задания 1, демонстрирующие динамическое управление памятью и распараллеливание с помощью OpenMP на C++.

## Структура проекта

- `task1.cpp`: Динамическое выделение массива, заполнение случайными числами, вычисление среднего значения.
- `task2_3.cpp`: Последовательный и параллельный (OpenMP) поиск минимума и максимума (1 млн элементов).
- `task4.cpp`: Последовательное и параллельное (OpenMP Reduction) вычисление среднего значения (5 млн элементов).
- `README.md`: этот файл.

## Компиляция и запуск

Убедитесь, что у вас установлен компилятор C++ с поддержкой OpenMP (например, GCC, Clang, MSVC).

### Компиляция
```bash
# Задание 1
g++ task1.cpp -o task1

# Задания 2 и 3
g++ -fopenmp task2_3.cpp -o task2_3

# Задание 4
g++ -fopenmp task4.cpp -o task4
```

### Запуск
```bash
./task1
./task2_3
./task4
```

---

## Контрольные вопросы (Ответы)

1.  **В чём отличие динамического массива от статического массива в языке C++?**
    *   **Статический**: Размер фиксируется на этапе компиляции, выделяется в стеке. Память управляется автоматически.
    *   **Динамический**: Размер определяется во время выполнения, выделяется в куче (используя `new` или `malloc`). Должен быть освобожден вручную (используя `delete[]` или `free`), чтобы избежать утечек.

2.  **Что такое указатель и зачем он используется при работе с динамической памятью?**
    *   Указатель — это переменная, хранящая адрес памяти другой переменной. Оператор `new` возвращает адрес выделенного блока в куче, поэтому нам нужен указатель для хранения этого адреса и доступа к динамической памяти.

3.  **Почему важно корректно освобождать память после использования динамических массивов?**
    *   Динамическая память не освобождается автоматически (в C/C++). Если ее не освободить, это приведет к **утечке памяти**, когда программа потребляет все больше и больше ОЗУ, пока система не исчерпает ресурсы или программа не завершится аварийно.

4.  **В чём разница между последовательной и параллельной обработкой массива?**
    *   **Последовательная**: Инструкции выполняются одна за другой на одном ядре процессора.
    *   **Параллельная**: Несколько инструкций выполняются одновременно на нескольких ядрах/потоках процессора, что потенциально ускоряет выполнение.

5.  **Что делает директива `#pragma omp parallel for`?**
    *   Это директива OpenMP, которая создает команду потоков и разделяет итерации следующего за ней цикла `for` между ними, так что итерации цикла выполняются параллельно.

6.  **Для чего используется механизм reduction в OpenMP?**
    *   Он безопасно объединяет частичные результаты, вычисленные каждым потоком, в одну общую переменную (например, суммирование чисел). Он автоматически обрабатывает "гонки данных".

7.  **Почему при параллельном вычислении суммы необходимо использовать reduction, а не обычную переменную?**
    *   Без reduction несколько потоков пытались бы записывать в переменную `sum` одновременно (состояние гонки), что привело бы к некорректным результатам. Атомарные операции безопаснее, но медленнее; reduction оптимизирован для таких задач.

8.  **Какие факторы могут привести к тому, что параллельная версия программы будет работать медленнее последовательной?**
    *   **Накладные расходы (Overhead)**: Создание/управление потоками занимает время. Если задача слишком мала, накладные расходы превысят время вычислений.
    *   **Ложное разделение (False Sharing)**: Потоки обновляют переменные, находящиеся на одной кэш-линии.
    *   **Критические секции/Блокировки**: Слишком долгое ожидание общих ресурсов.
    *   **Пропускная способность памяти**: Насыщение шины данных, если все ядра запрашивают данные одновременно.

---

## Блок-схемы (Flowcharts)

### Задание 1: Динамический массив и Среднее значение

```mermaid
flowchart TD
    start([Начало]) --> alloc[Выделение памяти: new int 50000]
    alloc --> check{Память выделена?}
    check -- Нет --> err[Вывод: Ошибка памяти]
    err --> stop([Конец])
    check -- Да --> initSum[Сумма = 0]
    initSum --> loopStart[Цикл i от 0 до 49999]
    loopStart --> randGen[Генерация числа 1-100]
    randGen --> arrSave[Запись в массив arr i]
    arrSave --> sumAdd[Сумма += arr i]
    sumAdd --> loopCond{i < 50000?}
    loopCond -- Да --> loopStart
    loopCond -- Нет --> calcAvg[Среднее = Сумма / 50000]
    calcAvg --> print[Вывод Суммы и Среднего]
    print --> delete[Освобождение памяти: delete arr]
    delete --> stop
```

### Задания 2 и 3: Поиск Мин/Макс (Послед. vs Параллельно)

```mermaid
flowchart TD
    start([Начало]) --> gen[Генерация массива 1 000 000 элементов]
    gen --> seqStart[Начало Sequential]
    seqStart --> timeStart1[Старт таймера]
    timeStart1 --> seqLoop[Цикл по массиву]
    seqLoop --> checkMin{Val < Min?}
    checkMin -- Да --> updMin[Min = Val]
    checkMin -- Нет --> checkMax{Val > Max?}
    checkMax -- Да --> updMax[Max = Val]
    checkMax -- Нет --> nextIter[Следующий элемент]
    updMin --> nextIter
    updMax --> nextIter
    nextIter --> seqCond{Конец массива?}
    seqCond -- Нет --> seqLoop
    seqCond -- Да --> timeStop1[Стоп таймера]
    
    timeStop1 --> parStart[Начало Parallel OpenMP]
    parStart --> timeStart2[Старт таймера]
    timeStart2 --> parRegion[#pragma omp parallel]
    parRegion --> split[Разделение на потоки]
    split --> localInit[Локальные min/max]
    localInit --> parLoop[#pragma omp for: Часть массива]
    parLoop --> localUpdates[Обновление локальных min/max]
    localUpdates --> loopAll{Все итерации?}
    loopAll -- Нет --> parLoop
    loopAll -- Да --> critical[#pragma omp critical]
    critical --> globalUpd[Обновление глобальных Min/Max]
    globalUpd --> join[Слияние потоков]
    join --> timeStop2[Стоп таймера]
    
    timeStop2 --> compare[Сравнение времени и результатов]
    compare --> stop([Конец])
```

### Задание 4: Вычисление Среднего (Послед. vs Параллельно)

```mermaid
flowchart TD
    start([Начало]) --> gen[Генерация массива 5 000 000 элементов]
    
    gen --> seqPath[Последовательное вычисление]
    seqPath --> time1[Старт таймера]
    time1 --> seqLoop[Цикл i: Sum += arr i]
    seqLoop --> time2[Стоп таймера]
    time2 --> seqRes[Среднее = Sum / Size]
    
    seqRes --> parPath[Параллельное вычисление OpenMP]
    parPath --> time3[Старт таймера]
    time3 --> parFork[Parallel Fork]
    parFork --> parLoop[#pragma omp parallel for reduction +:sum]
    parLoop --> threads[Потоки суммируют свои части]
    threads --> reduction[Reduction: Объединение сумм]
    reduction --> parJoin[Parallel Join]
    parJoin --> time4[Стоп таймера]
    time4 --> parRes[Среднее = Sum / Size]
    
    parRes --> output[Вывод результатов и ускорения]
    output --> stop([Конец])
```
